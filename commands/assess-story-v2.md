---
description: Comprehensive post-story health assessment tracking value delivery, quality, debt, and process metrics
allowed-tools: Read(*), Edit(*), Write(*), Bash(*), Grep(*), Glob(*)
argument-hint: <story-id>
---

# Assess Story V2 - Comprehensive Story Health Assessment

**Role:** You are the **Story Health Assessor** performing systematic 360Â° post-story evaluation to measure value delivery, code quality, technical debt, security posture, and process health in an AI-agent-first development environment.

**Usage:** `/assess-story-v2 <story-id>`

**Example:** `/assess-story-v2 1.2`

---

## Philosophy Shift: From Debt Auditor to Health Assessor

**V1 Focus:** What went wrong (deficit-oriented)
**V2 Focus:** Complete picture (value + quality + debt + process)

This assessment answers:
- âœ… **What did we build?** (Value Delivery)
- ğŸ“Š **How well did we build it?** (Quality Metrics)
- âš ï¸ **What do we owe?** (Technical Debt)
- ğŸ‰ **What did we fix?** (Debt Repayment)
- ğŸ”’ **What risks emerged?** (Security & Dependencies)
- ğŸ“ˆ **How did we work?** (Process Health)

---

## Prerequisites

**Required Tools:**
- git (for analysis)
- bash 4.0+ (for arithmetic operations)
- Standard Unix tools: grep, awk, wc, find

**Optional Tools (graceful degradation if missing):**
- uv + pytest (for test execution and coverage)
- radon (for complexity analysis via `uv pip install radon`)
- mypy (for type checking)

**Environment Setup:**
Before running, set the story ID:
```bash
export STORY_ID="1.2"  # Replace with your story number
```

**Note on Placeholders:**
- `${STORY_ID}` - Bash variable (must be set in environment)
- `{story-id}` - File path placeholder (replace manually or use sed)
- All bash examples assume `STORY_ID` is exported

---

## Workflow Overview

1. **Prerequisites Check** - Validate tools and environment
2. **Context Phase** - Determine git range, story scope, and baseline
3. **Value Analysis** - Measure what was delivered
4. **Quality Analysis** - Assess code quality metrics
5. **Debt Analysis** - Identify technical debt (V1 checks + more)
6. **Repayment Analysis** - Track debt paid down
7. **Security Analysis** - Evaluate security and dependency changes
8. **Performance Analysis** - Check for performance trends
9. **Process Analysis** - Review workflow health
10. **Comprehensive Test Coverage** - Measure test coverage
11. **Document Generation** - Create comprehensive assessment
12. **Summary Report** - Display actionable insights

---

## Phase 0: Prerequisites Check

### Step 0.1: Validate Environment

```bash
# Check story ID is set
if [ -z "${STORY_ID}" ]; then
    echo "ERROR: STORY_ID environment variable not set"
    echo "Usage: export STORY_ID='1.2' && /assess-story-v2 1.2"
    exit 1
fi

echo "Assessing Story: ${STORY_ID}"
echo "Assessment Date: $(date +%Y-%m-%d)"
ASSESSMENT_DATE=$(date +%Y%m%d)
```

### Step 0.2: Check Required Tools

```bash
# Required tools
command -v git >/dev/null 2>&1 || { echo "ERROR: git not found"; exit 1; }
command -v grep >/dev/null 2>&1 || { echo "ERROR: grep not found"; exit 1; }
command -v awk >/dev/null 2>&1 || { echo "ERROR: awk not found"; exit 1; }

echo "âœ“ Required tools available"
```

### Step 0.3: Check Optional Tools

```bash
# Optional tools (warn but continue)
if ! command -v uv >/dev/null 2>&1; then
    echo "WARNING: uv not found - test execution and coverage will be skipped"
fi

if command -v uv >/dev/null 2>&1; then
    if ! uv pip list 2>/dev/null | grep -q radon; then
        echo "WARNING: radon not installed - complexity analysis will be skipped"
        echo "Install with: uv pip install radon"
    fi
fi

echo "âœ“ Prerequisites check complete"
```

### Step 0.4: Create State File

```bash
# Create state file for variable persistence across phases
STATE_FILE="/tmp/assess-${STORY_ID//\./\_}-state-$$.sh"
trap "rm -f ${STATE_FILE}" EXIT

echo "export STORY_ID='${STORY_ID}'" > "${STATE_FILE}"
echo "export ASSESSMENT_DATE='${ASSESSMENT_DATE}'" >> "${STATE_FILE}"

echo "âœ“ State file created: ${STATE_FILE}"
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "Beginning Assessment: Story ${STORY_ID}"
echo "Estimated time: 5-10 minutes"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
```

---

## Phase 1: Context & Baseline

### Step 1.1: Determine Git Range

```bash
echo "Phase 1/11: Context & Baseline (est. 30s)..."

# Find the story planning commit
PLANNING_COMMIT=$(git log --oneline --grep="docs(story-${STORY_ID}): add test design and atomic commit plan" -1 --format="%H")

# Validate planning commit was found
if [ -z "${PLANNING_COMMIT}" ]; then
    echo "ERROR: Could not find planning commit for story ${STORY_ID}"
    echo "Expected commit message: docs(story-${STORY_ID}): add test design and atomic commit plan"
    exit 1
fi

# Get current HEAD
HEAD_COMMIT=$(git rev-parse HEAD)

# Count commits in story
COMMIT_COUNT=$(git rev-list ${PLANNING_COMMIT}..HEAD --count)

echo "Story Range: ${PLANNING_COMMIT:0:8}..${HEAD_COMMIT:0:8} (${COMMIT_COUNT} commits)"

# Save to state file
echo "export PLANNING_COMMIT='${PLANNING_COMMIT}'" >> "${STATE_FILE}"
echo "export HEAD_COMMIT='${HEAD_COMMIT}'" >> "${STATE_FILE}"
echo "export COMMIT_COUNT='${COMMIT_COUNT}'" >> "${STATE_FILE}"
```

### Step 1.2: Load Story Context

```bash
# Read story file
if [ ! -f "docs/stories/${STORY_ID}.md" ]; then
    echo "WARNING: Story file not found: docs/stories/${STORY_ID}.md"
else
    cat "docs/stories/${STORY_ID}.md"
fi

# Read test design
if [ ! -f "docs/qa/test-designs/${STORY_ID}-test-design.md" ]; then
    echo "WARNING: Test design not found: docs/qa/test-designs/${STORY_ID}-test-design.md"
else
    cat "docs/qa/test-designs/${STORY_ID}-test-design.md"
fi

# Read atomic commit plan
if [ ! -f "docs/qa/test-designs/${STORY_ID}-atomic-commits.md" ]; then
    echo "WARNING: Atomic commit plan not found: docs/qa/test-designs/${STORY_ID}-atomic-commits.md"
else
    cat "docs/qa/test-designs/${STORY_ID}-atomic-commits.md"
fi
```

**Extract:**
- Story title and objectives
- Acceptance criteria count
- Planned atomic commits count
- Story complexity estimate

### Step 1.3: Establish Baseline Metrics

```bash
# Get baseline stats from planning commit (non-destructive - no checkout)
# Note: Using git grep at specific commit instead of checking out

# Count existing technical debt at baseline using git grep
BASELINE_TYPE_IGNORES=$(git grep -n "type: ignore" ${PLANNING_COMMIT} -- 'src/**/*.py' 'tests/**/*.py' 2>/dev/null | wc -l || echo "0")
BASELINE_TODOS=$(git grep -nE "TODO|FIXME" ${PLANNING_COMMIT} -- 'src/**/*.py' 'tests/**/*.py' 2>/dev/null | wc -l || echo "0")

# Count LOC at baseline
BASELINE_LOC=$(git ls-tree -r ${PLANNING_COMMIT} --name-only | grep "^src/.*\.py$" | xargs -I {} git show ${PLANNING_COMMIT}:{} 2>/dev/null | wc -l || echo "0")

echo "Baseline: ${BASELINE_LOC} LOC, ${BASELINE_TYPE_IGNORES} type ignores, ${BASELINE_TODOS} TODOs"

# Save to state file
echo "export BASELINE_TYPE_IGNORES='${BASELINE_TYPE_IGNORES}'" >> "${STATE_FILE}"
echo "export BASELINE_TODOS='${BASELINE_TODOS}'" >> "${STATE_FILE}"
echo "export BASELINE_LOC='${BASELINE_LOC}'" >> "${STATE_FILE}"
```

---

## Phase 2: Value Delivery Analysis

### Step 2.1: Production Code Changes

```bash
echo "Phase 2/11: Value Delivery Analysis (est. 30s)..."

# Lines of code added/removed/changed
git diff ${PLANNING_COMMIT} HEAD --numstat -- 'src/**/*.py' | awk '{added+=$1; removed+=$2} END {print "Added: "added" Removed: "removed" Net: "(added-removed)}'

# Files changed in src/
FILES_CHANGED=$(git diff ${PLANNING_COMMIT} HEAD --name-only -- 'src/**/*.py' | wc -l || echo "0")

# New files created
NEW_FILES=$(git diff ${PLANNING_COMMIT} HEAD --name-status -- 'src/**/*.py' | grep "^A" | wc -l || echo "0")

# Functions added (NOTE: This is a heuristic - may include comments/docstrings)
FUNCTIONS_ADDED=$(git diff ${PLANNING_COMMIT} HEAD -- 'src/**/*.py' | grep "^+def " | wc -l || echo "0")

# Classes added (NOTE: This is a heuristic - may include comments/docstrings)
CLASSES_ADDED=$(git diff ${PLANNING_COMMIT} HEAD -- 'src/**/*.py' | grep "^+class " | wc -l || echo "0")

echo "Files changed: ${FILES_CHANGED}, New files: ${NEW_FILES}, Functions added: ~${FUNCTIONS_ADDED}, Classes added: ~${CLASSES_ADDED}"
```

**Output:** Production code metrics (LOC added, files changed, new functions/classes)

### Step 2.2: Test Code Changes

```bash
# Test lines added
git diff ${PLANNING_COMMIT} HEAD --numstat -- 'tests/**/*.py' | awk '{added+=$1; removed+=$2} END {print "Test LOC Added: "added" Removed: "removed}'

# Test files created
TEST_FILES_CREATED=$(git diff ${PLANNING_COMMIT} HEAD --name-status -- 'tests/**/*.py' | grep "^A" | wc -l || echo "0")

# Test functions added
TEST_FUNCTIONS_ADDED=$(git diff ${PLANNING_COMMIT} HEAD -- 'tests/**/*.py' | grep "^+def test_" | wc -l || echo "0")

# Test assertions added (rough estimate - heuristic only)
TEST_ASSERTIONS=$(git diff ${PLANNING_COMMIT} HEAD -- 'tests/**/*.py' | grep -c "^+.*assert " || echo "0")

echo "Test files: ${TEST_FILES_CREATED}, Test functions: ${TEST_FUNCTIONS_ADDED}, Assertions: ~${TEST_ASSERTIONS}"
```

**Output:** Test coverage expansion metrics

### Step 2.3: Documentation Changes

```bash
# Docstrings added/improved
DOCSTRINGS_ADDED=$(git diff ${PLANNING_COMMIT} HEAD -- 'src/**/*.py' | grep -E '^\+\s+"""' | wc -l || echo "0")

# README changes
git diff ${PLANNING_COMMIT} HEAD --numstat -- 'README.md' | awk '{print "README: +"$1" -"$2}'

# New ADRs
NEW_ADRS=$(git diff ${PLANNING_COMMIT} HEAD --name-status -- 'docs/adr/*.md' | grep "^A" | wc -l || echo "0")

# Documentation files changed (excluding test-designs and stories)
DOCS_CHANGED=$(git diff ${PLANNING_COMMIT} HEAD --name-only -- 'docs/**/*.md' | grep -v "qa/test-designs\|stories" | wc -l || echo "0")

echo "Docstrings: ${DOCSTRINGS_ADDED}, ADRs: ${NEW_ADRS}, Docs changed: ${DOCS_CHANGED}"
```

**Output:** Documentation improvements

### Step 2.4: Acceptance Criteria Verification

```bash
# Extract acceptance criteria from story file using unique temp file
TEMP_AC_FILE="/tmp/assess-${STORY_ID//\./\_}-ac-$$.txt"

if [ -f "docs/stories/${STORY_ID}.md" ]; then
    grep -A 100 "^## Acceptance Criteria" "docs/stories/${STORY_ID}.md" | grep "^- \[" > "${TEMP_AC_FILE}"

    # Count total vs. completed
    TOTAL_AC=$(wc -l < "${TEMP_AC_FILE}" || echo "0")
    COMPLETED_AC=$(grep -c "\[x\]" "${TEMP_AC_FILE}" || echo "0")

    echo "Acceptance Criteria: ${COMPLETED_AC}/${TOTAL_AC} completed"

    # Clean up temp file
    rm -f "${TEMP_AC_FILE}"
else
    echo "WARNING: Cannot verify acceptance criteria - story file not found"
    TOTAL_AC=0
    COMPLETED_AC=0
fi
```

**Output:** Acceptance criteria completion rate

---

## Phase 3: Code Quality Analysis

### Step 3.1: Complexity Metrics

```bash
echo "Phase 3/11: Code Quality Analysis (est. 1-2 min)..."

# Check if radon is available
if ! command -v uv >/dev/null 2>&1 || ! uv pip list 2>/dev/null | grep -q radon; then
    echo "SKIPPED: radon not available - install with 'uv pip install radon'"
else
    # Cyclomatic complexity for changed files
    echo "Analyzing cyclomatic complexity..."
    git diff ${PLANNING_COMMIT} HEAD --name-only -- 'src/**/*.py' | while read file; do
        if [ -f "$file" ]; then
            echo "=== $file ==="
            uv run radon cc "$file" -s -a 2>/dev/null || echo "  (analysis failed)"
        fi
    done

    # Maintainability index
    echo "Analyzing maintainability index..."
    git diff ${PLANNING_COMMIT} HEAD --name-only -- 'src/**/*.py' | while read file; do
        if [ -f "$file" ]; then
            uv run radon mi "$file" -s 2>/dev/null || echo "  $file: (analysis failed)"
        fi
    done
fi
```

**Output:** Complexity scores and maintainability indices

### Step 3.2: Function Size Analysis

```bash
# Find long functions (>50 lines)
git diff ${PLANNING_COMMIT} HEAD --name-only -- 'src/**/*.py' | while read file; do
    if [ -f "$file" ]; then
        uv run radon raw "$file" | grep -E "LOC:|LLOC:"
    fi
done
```

**Output:** Functions exceeding size thresholds

### Step 3.3: Type Annotation Coverage

```bash
# Check for functions without type hints in new/changed code
git diff ${PLANNING_COMMIT} HEAD -- 'src/**/*.py' | grep "^+def " | grep -v " -> " | head -20
```

**Output:** Functions missing return type annotations

### Step 3.4: Code Duplication Detection

```bash
# Find similar function names (V1 check)
find src/momo -name "*.py" -exec grep -h "^def " {} \; | sort | uniq -d

# Use simple similarity detection
git diff ${PLANNING_COMMIT} HEAD --name-only -- 'src/**/*.py' | while read file; do
    if [ -f "$file" ]; then
        # Look for repeated code blocks (simple heuristic)
        grep -n "def \|class " "$file"
    fi
done
```

**Output:** Duplication candidates

---

## Phase 4: Technical Debt Analysis (Enhanced V1)

### Step 4.1: Type Safety Debt

```bash
echo "Phase 4/11: Technical Debt Analysis (est. 30s)..."

# Type ignores added (V1) - with safe fallback
TYPE_IGNORES_ADDED=$(git diff ${PLANNING_COMMIT} HEAD --unified=0 | grep "^+.*type: ignore" | wc -l || echo "0")
TYPE_IGNORES_ADDED=${TYPE_IGNORES_ADDED:-0}  # Ensure numeric

# Type ignores removed (NEW) - with safe fallback
TYPE_IGNORES_REMOVED=$(git diff ${PLANNING_COMMIT} HEAD --unified=0 | grep "^-.*type: ignore" | wc -l || echo "0")
TYPE_IGNORES_REMOVED=${TYPE_IGNORES_REMOVED:-0}  # Ensure numeric

# Calculate net change safely
NET_TYPE_IGNORES=$((TYPE_IGNORES_ADDED - TYPE_IGNORES_REMOVED))

echo "Type ignores: +${TYPE_IGNORES_ADDED} -${TYPE_IGNORES_REMOVED} (net: ${NET_TYPE_IGNORES})"

# Show added type ignores if any
if [ ${TYPE_IGNORES_ADDED} -gt 0 ]; then
    echo "Added type ignores:"
    git diff ${PLANNING_COMMIT} HEAD --unified=0 | grep "^+.*type: ignore"
fi

# Save to state file
echo "export TYPE_IGNORES_ADDED='${TYPE_IGNORES_ADDED}'" >> "${STATE_FILE}"
echo "export TYPE_IGNORES_REMOVED='${TYPE_IGNORES_REMOVED}'" >> "${STATE_FILE}"
echo "export NET_TYPE_IGNORES='${NET_TYPE_IGNORES}'" >> "${STATE_FILE}"
```

**Output:** Type safety debt added AND removed

### Step 4.2: TODO/FIXME Tracking

```bash
# TODOs added (V1) - with safe fallback
TODOS_ADDED=$(git diff ${PLANNING_COMMIT} HEAD --unified=0 | grep -E "^\+.*TODO|^\+.*FIXME" | wc -l || echo "0")
TODOS_ADDED=${TODOS_ADDED:-0}  # Ensure numeric

# TODOs removed (NEW) - with safe fallback
TODOS_REMOVED=$(git diff ${PLANNING_COMMIT} HEAD --unified=0 | grep -E "^-.*TODO|^-.*FIXME" | wc -l || echo "0")
TODOS_REMOVED=${TODOS_REMOVED:-0}  # Ensure numeric

# Calculate net change safely
NET_TODOS=$((TODOS_ADDED - TODOS_REMOVED))

echo "TODOs: +${TODOS_ADDED} -${TODOS_REMOVED} (net: ${NET_TODOS})"

# Show added TODOs if any
if [ ${TODOS_ADDED} -gt 0 ]; then
    echo "Added TODOs/FIXMEs:"
    git diff ${PLANNING_COMMIT} HEAD --unified=0 | grep -E "^\+.*TODO|^\+.*FIXME"
fi

# Save to state file
echo "export TODOS_ADDED='${TODOS_ADDED}'" >> "${STATE_FILE}"
echo "export TODOS_REMOVED='${TODOS_REMOVED}'" >> "${STATE_FILE}"
echo "export NET_TODOS='${NET_TODOS}'" >> "${STATE_FILE}"
```

**Output:** TODO debt with net change

### Step 4.3: Architecture Compliance

```bash
# NOTE: These checks are PROJECT-SPECIFIC examples from the Momo codebase
# Adapt these patterns to your project's architecture rules

# Example: Check layer violations (Momo-specific layered architecture)
if [ -d "src/momo" ]; then
    echo "Checking Momo-specific architecture compliance..."

    # Layer violations
    grep -r "from momo.backtest\|from momo.portfolio" src/momo/signals/ 2>/dev/null || echo "  âœ“ No violations in signals/"
    grep -r "from momo.backtest" src/momo/portfolio/ 2>/dev/null || echo "  âœ“ No violations in portfolio/"
    grep -r "import norgatedata\|from norgatedata" src/momo/ 2>/dev/null | grep -v "src/momo/data/bridge.py" || echo "  âœ“ No violations in norgatedata usage"

    # Mutation detection in pure function layers
    grep -r "def calculate_\|def rank_\|def construct_" src/momo/signals/ src/momo/portfolio/ -A 10 2>/dev/null | grep -v "\.copy()" | grep -E "^\s*[a-z_]+\[" || echo "  âœ“ No obvious mutations detected"
else
    echo "SKIPPED: Architecture checks (no Momo-specific structure found)"
    echo "  Customize this section for your project's architecture rules"
fi
```

**Output:** Architecture violations (project-specific checks)

### Step 4.4: Test Infrastructure Debt (V1)

```bash
# Fixtures needing promotion
find tests/stories/${STORY_ID} -name conftest.py 2>/dev/null
if [ -f tests/stories/${STORY_ID}/conftest.py ]; then
    grep "^def \|^@pytest.fixture" tests/stories/${STORY_ID}/conftest.py
fi

# Test naming compliance
find tests/stories/${STORY_ID} -name "test_*.py" 2>/dev/null | grep -v -E "test_[0-9]+\.[0-9]+_(unit|integration|e2e)_[0-9]+\.py" || echo "âœ“ All test files follow naming convention"

# Test marker consistency
for test_file in tests/stories/${STORY_ID}/*/*/test_*.py 2>/dev/null; do
    if ! grep -q "@pytest.mark.p[012]" "$test_file"; then
        echo "Missing priority marker: $test_file"
    fi
    if ! grep -q "@pytest.mark.\(unit\|integration\|e2e\)" "$test_file"; then
        echo "Missing level marker: $test_file"
    fi
done
```

**Output:** Test organization issues (V1 checks)

---

## Phase 5: Debt Repayment Analysis (NEW)

### Step 5.1: Technical Debt Resolved

```bash
# Calculate net debt changes (from Step 4)
echo "=== Debt Repayment Summary ==="
echo "Type ignores removed: ${TYPE_IGNORES_REMOVED}"
echo "TODOs resolved: ${TODOS_REMOVED}"

# Check for duplicate code removed
git diff ${PLANNING_COMMIT} HEAD --unified=0 | grep "^-def " | wc -l

# Check for simplified complexity (functions removed/refactored)
echo "Functions removed: $(git diff ${PLANNING_COMMIT} HEAD --unified=0 | grep "^-def " | wc -l)"
```

**Output:** Debt actively paid down

### Step 5.2: Refactoring Impact

```bash
# Files with net LOC reduction (refactoring candidates)
git diff ${PLANNING_COMMIT} HEAD --numstat -- 'src/**/*.py' | awk '$2 > $1 {print $3" (removed "($2-$1)" lines)"}'
```

**Output:** Refactoring activities

### Step 5.3: Test Cleanup

```bash
# Obsolete tests removed
git diff ${PLANNING_COMMIT} HEAD --name-status -- 'tests/**/*.py' | grep "^D" | wc -l

# Fixtures consolidated
git diff ${PLANNING_COMMIT} HEAD -- 'tests/conftest.py' | grep "^+@pytest.fixture" | wc -l
```

**Output:** Test infrastructure improvements

---

## Phase 6: Security & Dependency Analysis (NEW)

### Step 6.1: Dependency Changes

```bash
echo "Phase 6/11: Security & Dependency Analysis (est. 30s)..."

# Check pyproject.toml changes
if [ -f "pyproject.toml" ]; then
    git diff ${PLANNING_COMMIT} HEAD -- pyproject.toml

    # Count new dependencies - safe fallback
    NEW_DEPS=$(git diff ${PLANNING_COMMIT} HEAD -- pyproject.toml | grep "^+" | grep -c "=" || echo "0")
    NEW_DEPS=${NEW_DEPS:-0}
    echo "New dependencies added: ${NEW_DEPS}"

    # List new dependencies if any
    if [ ${NEW_DEPS} -gt 0 ]; then
        echo "New dependency lines:"
        git diff ${PLANNING_COMMIT} HEAD -- pyproject.toml | grep "^+" | grep "="
    fi
else
    echo "SKIPPED: No pyproject.toml found"
    NEW_DEPS=0
fi
```

**Output:** Dependency additions

### Step 6.2: Security Pattern Detection

```bash
# WARNING: These are HEURISTIC checks only - expect false positives
# All findings require manual review to determine if they are actual security issues

echo "Running heuristic security pattern detection (manual review required)..."

# Check for hardcoded secrets patterns (heuristic - may have false positives)
SECRETS_COUNT=$(git diff ${PLANNING_COMMIT} HEAD -- 'src/**/*.py' | grep -iE "password|secret|api_key|token" | grep "=" | wc -l || echo "0")
if [ ${SECRETS_COUNT:-0} -gt 0 ]; then
    echo "âš ï¸  Found ${SECRETS_COUNT} potential secret patterns (review manually):"
    git diff ${PLANNING_COMMIT} HEAD -- 'src/**/*.py' | grep -iE "password|secret|api_key|token" | grep "=" | head -10
fi

# Check for SQL injection risks (heuristic - may have false positives)
SQL_COUNT=$(git diff ${PLANNING_COMMIT} HEAD -- 'src/**/*.py' | grep -E "execute\(.*%|execute\(.*format" | wc -l || echo "0")
if [ ${SQL_COUNT:-0} -gt 0 ]; then
    echo "âš ï¸  Found ${SQL_COUNT} potential SQL injection patterns (review manually):"
    git diff ${PLANNING_COMMIT} HEAD -- 'src/**/*.py' | grep -E "execute\(.*%|execute\(.*format" | head -10
fi

# Check for shell injection risks (heuristic - may have false positives)
SHELL_COUNT=$(git diff ${PLANNING_COMMIT} HEAD -- 'src/**/*.py' | grep -E "subprocess\.|os\.system|shell=True" | wc -l || echo "0")
if [ ${SHELL_COUNT:-0} -gt 0 ]; then
    echo "âš ï¸  Found ${SHELL_COUNT} potential shell injection patterns (review manually):"
    git diff ${PLANNING_COMMIT} HEAD -- 'src/**/*.py' | grep -E "subprocess\.|os\.system|shell=True" | head -10
fi

# Check for path traversal risks (heuristic - may have false positives)
PATH_COUNT=$(git diff ${PLANNING_COMMIT} HEAD -- 'src/**/*.py' | grep -E "open\(.*\+|Path\(.*\+" | wc -l || echo "0")
if [ ${PATH_COUNT:-0} -gt 0 ]; then
    echo "âš ï¸  Found ${PATH_COUNT} potential path traversal patterns (review manually):"
    git diff ${PLANNING_COMMIT} HEAD -- 'src/**/*.py' | grep -E "open\(.*\+|Path\(.*\+" | head -10
fi

if [ ${SECRETS_COUNT:-0} -eq 0 ] && [ ${SQL_COUNT:-0} -eq 0 ] && [ ${SHELL_COUNT:-0} -eq 0 ] && [ ${PATH_COUNT:-0} -eq 0 ]; then
    echo "âœ“ No obvious security patterns detected (patterns are heuristic only)"
fi
```

**Output:** Potential security issues (HEURISTIC - requires manual review)

### Step 6.3: Sensitive File Checks

```bash
# Check for sensitive files added
git diff ${PLANNING_COMMIT} HEAD --name-status | grep -E "\.env|credentials|secrets|\.key|\.pem"

# Check for data files added (should be in .gitignore)
git diff ${PLANNING_COMMIT} HEAD --name-status -- 'data/**/*' | grep "^A"
```

**Output:** Sensitive file changes

---

## Phase 7: Performance Analysis (NEW)

### Step 7.1: Test Execution Time

```bash
echo "Phase 7/11: Performance Analysis (est. 1-3 min)..."

# Check if test directory exists and uv is available
if [ ! -d "tests/stories/${STORY_ID}" ]; then
    echo "SKIPPED: No test directory found at tests/stories/${STORY_ID}/"
elif ! command -v uv >/dev/null 2>&1; then
    echo "SKIPPED: uv not available for running tests"
else
    # Run story tests with timing
    echo "Running tests with timing analysis..."
    uv run pytest tests/stories/${STORY_ID}/ -v --durations=10 2>&1 | grep "slowest" || echo "  (no timing data available)"

    # Calculate total test time
    TEST_TIME=$(uv run pytest tests/stories/${STORY_ID}/ -v 2>&1 | grep "passed in" | grep -oE "[0-9]+\.[0-9]+s" || echo "unknown")
    echo "Story test suite execution time: ${TEST_TIME}"
fi
```

**Output:** Test performance metrics

### Step 7.2: Code Performance Patterns

```bash
# Check for nested loops (potential O(nÂ²) issues)
git diff ${PLANNING_COMMIT} HEAD -- 'src/**/*.py' | grep -A 3 "^+.*for.*in" | grep "for.*in" | head -10

# Check for repeated DataFrame operations (should batch)
git diff ${PLANNING_COMMIT} HEAD -- 'src/**/*.py' | grep -E "for.*iterrows|for.*in df\[" | head -10
```

**Output:** Performance risk patterns

### Step 7.3: Build Time Impact

```bash
# Check for large file additions
git diff ${PLANNING_COMMIT} HEAD --stat | tail -1
```

**Output:** Build/package size impact

---

## Phase 8: Process Health Analysis (NEW)

### Step 8.1: Commit Quality

```bash
echo "Phase 8/11: Process Health Analysis (est. 30s)..."

# Count atomic commits - safe fallback
ATOMIC_COMMITS=$(git log ${PLANNING_COMMIT}..HEAD --oneline | wc -l || echo "0")
ATOMIC_COMMITS=${ATOMIC_COMMITS:-0}

# Count fix/rollback commits - safe fallback
FIX_COMMITS=$(git log ${PLANNING_COMMIT}..HEAD --oneline | grep -iE "fix|rollback|revert" | wc -l || echo "0")
FIX_COMMITS=${FIX_COMMITS:-0}

# Calculate fix ratio safely
if [ ${ATOMIC_COMMITS} -gt 0 ]; then
    FIX_RATIO=$((FIX_COMMITS * 100 / ATOMIC_COMMITS))
else
    FIX_RATIO=0
fi

echo "Commits: ${ATOMIC_COMMITS} total, ${FIX_COMMITS} fixes/rollbacks (${FIX_RATIO}% fix ratio)"

# List commit messages
echo "=== Commit Messages ==="
git log ${PLANNING_COMMIT}..HEAD --oneline
```

**Output:** Commit quality metrics

### Step 8.2: Scope Discipline

```bash
# Check for commits outside story scope (analyze commit messages)
git log ${PLANNING_COMMIT}..HEAD --oneline | grep -v "story-{story-id}\|{story-id}" || echo "âœ“ All commits properly scoped"

# Check for unplanned files changed
git diff ${PLANNING_COMMIT} HEAD --name-only | grep -v "^src/\|^tests/stories/${STORY_ID}\|^docs/" || echo "âœ“ No unexpected file changes"
```

**Output:** Scope creep detection

### Step 8.3: CI/CD Health

```bash
# Check for pre-commit config changes
git diff ${PLANNING_COMMIT} HEAD -- .pre-commit-config.yaml

# Check for CI config changes
git diff ${PLANNING_COMMIT} HEAD -- .github/workflows/
```

**Output:** CI/CD changes

---

## Phase 9: Comprehensive Test Coverage

### Step 9.1: Story-Specific Coverage

```bash
echo "Phase 9/11: Test Coverage Analysis (est. 1-3 min)..."

# Check prerequisites
if ! command -v uv >/dev/null 2>&1; then
    echo "SKIPPED: uv not available for coverage analysis"
elif [ ! -d "tests/stories/${STORY_ID}" ]; then
    echo "SKIPPED: No test directory found at tests/stories/${STORY_ID}/"
else
    # Run coverage for story tests
    echo "Running coverage analysis for story tests..."
    uv run pytest tests/stories/${STORY_ID}/ --cov=src --cov-report=term-missing --quiet 2>&1 | tail -30 || echo "  (coverage analysis failed)"
fi
```

**Output:** Detailed coverage report

### Step 9.2: Coverage Delta

```bash
# NOTE: Coverage delta measurement is optional and may be skipped if it takes too long
# or if dependencies have changed between baseline and current

if ! command -v uv >/dev/null 2>&1; then
    echo "SKIPPED: uv not available for coverage delta"
else
    echo "Attempting coverage delta measurement (this may take a while)..."

    # Get current coverage
    CURRENT_COV=$(uv run pytest --cov=src --cov-report=term --quiet 2>&1 | grep "^TOTAL" | awk '{print $4}' || echo "unknown")

    # Baseline coverage is challenging to measure without checkout
    # Option 1: Skip baseline (faster, less risky)
    # Option 2: Use git worktree (safer than checkout but complex)
    # For now, we'll skip baseline and just report current

    echo "Current Coverage: ${CURRENT_COV}"
    echo "Note: Baseline coverage measurement skipped (would require git checkout or worktree)"
    echo "      To measure baseline, manually checkout ${PLANNING_COMMIT:0:8} and run coverage"
fi
```

**Output:** Coverage trend (baseline measurement optional)

---

## Phase 10: Document Generation

### Step 10.1: Create Comprehensive Assessment Report

```bash
echo "Phase 10/11: Document Generation (est. 30s)..."

# Create assessments directory if needed
mkdir -p docs/qa/assessments

# Set output file path
ASSESSMENT_FILE="docs/qa/assessments/${STORY_ID}-health-assessment-${ASSESSMENT_DATE}.md"

echo "Creating assessment report: ${ASSESSMENT_FILE}"
```

Create `docs/qa/assessments/${STORY_ID}-health-assessment-${ASSESSMENT_DATE}.md` with the following template:

```markdown
# Story {story-id} - Comprehensive Health Assessment

**Assessment Date:** {current-date}
**Story Status:** {status from story file}
**Commit Range:** {PLANNING_COMMIT:0:8}..{HEAD_COMMIT:0:8} ({COMMIT_COUNT} commits)
**Assessor:** Claude Code (claude-sonnet-4-5-20250929)
**Assessment Model:** Story Health Assessment V2

---

## Executive Summary

Story {story-id} achieved an **Overall Health Score of {score}/100** ({grade}).

**Health Dimensions:**
- ğŸ¯ Value Delivery: {score}/100 ({grade})
- ğŸ“Š Code Quality: {score}/100 ({grade})
- âš ï¸ Technical Debt: {score}/100 ({grade})
- ğŸ‰ Debt Repayment: {score}/100 ({grade})
- ğŸ”’ Security Posture: {score}/100 ({grade})
- ğŸ“ˆ Process Health: {score}/100 ({grade})

**Key Highlights:**
- âœ… {positive highlight 1}
- âœ… {positive highlight 2}
- âš ï¸ {concern 1}
- âš ï¸ {concern 2}

**Recommendation:** {Ready for Production / Minor Cleanup Needed / Significant Issues to Address}

---

## 1. Value Delivery ({score}/100)

### 1.1 Production Code Delivered

| Metric | Value |
|--------|-------|
| Lines Added | {count} |
| Lines Removed | {count} |
| Net Change | {count} |
| Files Changed | {count} |
| New Files | {count} |
| Functions Added | {count} |
| Classes Added | {count} |

**Assessment:** {evaluation of code volume and changes}

### 1.2 Test Coverage Expansion

| Metric | Value |
|--------|-------|
| Test LOC Added | {count} |
| Test Files Created | {count} |
| Test Functions Added | {count} |
| Test Assertions Added | ~{count} |
| Test/Code Ratio | {ratio} |

**Assessment:** {evaluation of test coverage growth}

### 1.3 Documentation Improvements

| Metric | Value |
|--------|-------|
| Docstrings Added | {count} |
| README Changes | {+/-} |
| New ADRs | {count} |
| Docs Updated | {count} |

**Assessment:** {evaluation of documentation quality}

### 1.4 Acceptance Criteria Completion

**Completion Rate:** {COMPLETED_AC}/{TOTAL_AC} ({percentage}%)

**Status:**
{list of acceptance criteria with completion status}

**Assessment:** {evaluation of story completion}

### Value Delivery Score Calculation

- Production code volume: {subscore}
- Test coverage expansion: {subscore}
- Documentation quality: {subscore}
- AC completion rate: {subscore}

**Total Value Delivery Score:** {score}/100

---

## 2. Code Quality ({score}/100)

### 2.1 Complexity Metrics

**Cyclomatic Complexity:**
{list files with complexity scores}

**Maintainability Index:**
{list files with MI scores}

**Functions Exceeding Thresholds:**
{list functions > 50 lines or > complexity 10}

**Assessment:** {evaluation}

### 2.2 Type Safety

**Type Annotation Coverage:** {percentage}%

**Functions Missing Type Hints:**
{list or "All functions properly typed"}

**Assessment:** {evaluation}

### 2.3 Code Duplication

**Duplicate Patterns Detected:** {count}

{list duplication candidates or "âœ“ No significant duplication detected"}

**Assessment:** {evaluation}

### Code Quality Score Calculation

- Complexity: {subscore}
- Type coverage: {subscore}
- Duplication: {subscore}

**Total Code Quality Score:** {score}/100

---

## 3. Technical Debt ({score}/100)

### 3.1 Type Safety Debt

**Type Ignores Added:** {count}
**Type Ignores Removed:** {count}
**Net Change:** {+/-count}

{detailed list with file:line or "None"}

**Assessment:** {evaluation}

### 3.2 Code Organization Debt

**TODOs Added:** {count}
**TODOs Removed:** {count}
**Net Change:** {+/-count}

{detailed list or "None"}

**Assessment:** {evaluation}

### 3.3 Architecture Compliance

**Violations Detected:** {count}

{detailed list or "âœ“ Full compliance with layered architecture"}

**Assessment:** {evaluation}

### 3.4 Test Infrastructure Debt

**New Fixtures:** {count}
**Promotion Candidates:** {count}
**Naming Violations:** {count}
**Missing Markers:** {count}

{detailed findings}

**Assessment:** {evaluation}

### Technical Debt Score Calculation

- Type safety: {subscore}
- Code organization: {subscore}
- Architecture: {subscore}
- Test infrastructure: {subscore}

**Total Technical Debt Score:** {score}/100 (higher = less debt)

---

## 4. Debt Repayment ({score}/100)

### 4.1 Technical Debt Resolved

**Type Ignores Removed:** {count}
**TODOs Resolved:** {count}
**Duplicate Code Removed:** {count}
**Functions Refactored:** {count}

{detailed list of repayment activities}

**Assessment:** {evaluation}

### 4.2 Refactoring Impact

**Files Refactored (Net LOC Reduction):**
{list files with negative net changes}

**Assessment:** {evaluation}

### 4.3 Test Cleanup

**Obsolete Tests Removed:** {count}
**Fixtures Consolidated:** {count}

**Assessment:** {evaluation}

### Debt Repayment Score Calculation

- Debt items resolved: {subscore}
- Refactoring volume: {subscore}
- Test cleanup: {subscore}

**Total Debt Repayment Score:** {score}/100

---

## 5. Security Posture ({score}/100)

### 5.1 Dependency Changes

**New Dependencies:** {count}

{list new dependencies or "None"}

**Assessment:** {evaluation of supply chain risk}

### 5.2 Security Pattern Analysis

**Potential Issues Detected:** {count}

{list security concerns or "âœ“ No security patterns detected"}

**Categories Checked:**
- Hardcoded secrets: {pass/fail}
- SQL injection risks: {pass/fail}
- Shell injection risks: {pass/fail}
- Path traversal risks: {pass/fail}

**Assessment:** {evaluation}

### 5.3 Sensitive Files

**Sensitive Files Added:** {count}

{list or "None"}

**Assessment:** {evaluation}

### Security Posture Score Calculation

- Dependency risk: {subscore}
- Security patterns: {subscore}
- Sensitive file handling: {subscore}

**Total Security Posture Score:** {score}/100

---

## 6. Process Health ({score}/100)

### 6.1 Commit Quality

**Total Commits:** {count}
**Fix/Rollback Commits:** {count}
**Fix Ratio:** {percentage}%

**Commit History:**
{list commit messages}

**Assessment:** {evaluation of commit quality}

### 6.2 Scope Discipline

**Out-of-Scope Commits:** {count}
**Unplanned File Changes:** {count}

{list issues or "âœ“ Perfect scope discipline"}

**Assessment:** {evaluation}

### 6.3 Test Performance

**Story Test Suite Time:** {time}
**Slowest Tests:**
{list top 5 slowest tests}

**Assessment:** {evaluation}

### 6.4 CI/CD Changes

**Pre-commit Changes:** {yes/no}
**CI Pipeline Changes:** {yes/no}

**Assessment:** {evaluation}

### Process Health Score Calculation

- Commit quality: {subscore}
- Scope discipline: {subscore}
- Test performance: {subscore}
- CI/CD stability: {subscore}

**Total Process Health Score:** {score}/100

---

## 7. Overall Health Score

### Score Breakdown

| Dimension | Weight | Score | Weighted |
|-----------|--------|-------|----------|
| Value Delivery | 25% | {score} | {weighted} |
| Code Quality | 20% | {score} | {weighted} |
| Technical Debt | 20% | {score} | {weighted} |
| Debt Repayment | 15% | {score} | {weighted} |
| Security Posture | 10% | {score} | {weighted} |
| Process Health | 10% | {score} | {weighted} |
| **TOTAL** | **100%** | - | **{total}/100** |

**Overall Grade:** {A/B/C/D/F}

**Grade Interpretation:**
- 90-100 (A): Excellent - Production ready with exemplary quality
- 80-89 (B): Good - Production ready with minor observations
- 70-79 (C): Acceptable - Ready with cleanup tasks scheduled
- 60-69 (D): Needs Improvement - Cleanup required before next story
- 0-59 (F): Significant Issues - Immediate remediation needed

---

## 8. Recommended Actions

### ğŸ”´ Critical (Do Immediately)

{list critical actions or "None - story is healthy"}

### ğŸŸ¡ Important (Do Before Next Story)

{list important actions}

### ğŸŸ¢ Nice to Have (Backlog)

{list backlog items}

### ğŸ‰ Celebrate

{list positive achievements worth recognizing}

---

## 9. Trend Analysis

{if previous assessment exists, compare:}
- Overall health score trend: {â†‘/â†“/â†’}
- Value delivery trend: {â†‘/â†“/â†’}
- Debt accumulation trend: {â†‘/â†“/â†’}
- Debt repayment trend: {â†‘/â†“/â†’}

**Trajectory:** {improving/stable/concerning}

---

## 10. Consolidated Metrics Table

| Metric | Baseline | Current | Delta | Status |
|--------|----------|---------|-------|--------|
| Total LOC | {baseline} | {current} | {delta} | {â†‘/â†“/â†’} |
| Type Ignores | {baseline} | {current} | {delta} | {ğŸŸ¢/ğŸŸ¡/ğŸ”´} |
| TODOs | {baseline} | {current} | {delta} | {ğŸŸ¢/ğŸŸ¡/ğŸ”´} |
| Test Coverage | {baseline}% | {current}% | {delta}% | {ğŸŸ¢/ğŸŸ¡/ğŸ”´} |
| Dependencies | {baseline} | {current} | {delta} | {ğŸŸ¢/ğŸŸ¡/ğŸ”´} |
| Functions | {baseline} | {current} | {delta} | {â†‘/â†“/â†’} |
| Test Functions | {baseline} | {current} | {delta} | {â†‘/â†“/â†’} |

---

## 11. Quality Gates

### Story Completion Gate
- [ ] All acceptance criteria completed: {pass/fail}
- [ ] All planned commits executed: {pass/fail}
- [ ] No critical security issues: {pass/fail}
- [ ] Test coverage â‰¥ {target}%: {pass/fail}

### Code Quality Gate
- [ ] No architecture violations: {pass/fail}
- [ ] Type safety maintained: {pass/fail}
- [ ] Complexity within limits: {pass/fail}
- [ ] All tests pass: {pass/fail}

### Debt Management Gate
- [ ] Net type ignores â‰¤ 2: {pass/fail}
- [ ] Net TODOs â‰¤ 3: {pass/fail}
- [ ] All tests properly marked: {pass/fail}
- [ ] No obvious duplication: {pass/fail}

**Overall Gate Status:** {âœ… PASS / âš ï¸ PASS WITH NOTES / âŒ FAIL}

---

## Appendix A: Detailed Check Commands

Run these commands to verify findings:

```bash
# Value metrics
git diff {PLANNING_COMMIT} HEAD --numstat -- 'src/**/*.py'
git diff {PLANNING_COMMIT} HEAD --numstat -- 'tests/**/*.py'

# Technical debt
git diff {PLANNING_COMMIT} HEAD | grep "type: ignore"
git diff {PLANNING_COMMIT} HEAD | grep -E "TODO|FIXME"

# Architecture
grep -r "from momo.backtest" src/momo/signals/ src/momo/portfolio/

# Security
git diff {PLANNING_COMMIT} HEAD | grep -iE "password|secret|api_key"

# Test performance
uv run pytest tests/stories/{story-id}/ -v --durations=10

# Coverage
uv run pytest tests/stories/{story-id}/ --cov=src/momo --cov-report=term-missing
```

---

## Appendix B: Assessment Methodology

**Data Collection:** Automated git analysis and static code analysis
**Scoring Model:** Weighted multi-dimensional health model
**Baseline:** Planning commit as reference point
**Scope:** All changes from planning commit to HEAD
**Tools:** git, pytest, mypy, radon, grep, custom analysis scripts

---

**Assessment Complete** âœ“

Generated by: Claude Code V2 Story Health Assessor
```

### Step 10.2: Update docs/tech-debt.md (V1 format, enhanced)

Add story assessment section with net debt metrics:

```markdown
### Story {story-id} - {date}

**Overall Health:** {score}/100 ({grade})

**Value Delivered:**
- {summary of production code}
- {summary of tests}
- Acceptance Criteria: {completed}/{total}

**Debt Added/Removed:**
- Type Ignores: +{added} -{removed} (net: {net})
- TODOs: +{added} -{removed} (net: {net})
- Fixtures to Promote: {count}

**Debt Repayment:**
- {list of debt items resolved}

**Security:** {findings or "âœ“ No issues"}

**Recommendation:** {action items}
```

### Step 10.3: Update docs/type-ignore-registry.md (V1 format)

Same format as V1, but include net change context.

---

## Phase 11: Summary Report

Display comprehensive summary:

```bash
echo "Phase 11/11: Summary Report"
echo ""
```

```
ğŸ¥ Story ${STORY_ID} - Comprehensive Health Assessment Complete

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š OVERALL HEALTH: {score}/100 ({grade}) {status-emoji}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ VALUE DELIVERY: {score}/100
   â€¢ Production Code: {LOC-added} lines, {functions} functions, {files} files
   â€¢ Test Coverage: {test-LOC} lines, {test-count} tests, {assertions} assertions
   â€¢ Documentation: {docstrings} docstrings, {docs-updated} files updated
   â€¢ Acceptance Criteria: {completed}/{total} completed ({percentage}%)

ğŸ“Š CODE QUALITY: {score}/100
   â€¢ Complexity: {average-complexity} avg, {high-complexity-count} high
   â€¢ Type Coverage: {percentage}%
   â€¢ Duplication: {count} patterns detected

âš ï¸ TECHNICAL DEBT: {score}/100 (higher = less debt)
   â€¢ Type Ignores: +{added} -{removed} (net: {net})
   â€¢ TODOs: +{added} -{removed} (net: {net})
   â€¢ Architecture: {violations-count} violations
   â€¢ Test Infrastructure: {issues-count} issues

ğŸ‰ DEBT REPAYMENT: {score}/100
   â€¢ Type Ignores Removed: {count}
   â€¢ TODOs Resolved: {count}
   â€¢ Code Refactored: {files-count} files
   â€¢ Tests Cleaned: {count} obsolete tests removed

ğŸ”’ SECURITY POSTURE: {score}/100
   â€¢ Dependencies Added: {count}
   â€¢ Security Patterns: {count} potential issues
   â€¢ Sensitive Files: {count} changes

ğŸ“ˆ PROCESS HEALTH: {score}/100
   â€¢ Commits: {total-commits} ({fix-commits} fixes, {fix-ratio}% fix ratio)
   â€¢ Scope Discipline: {violations-count} out-of-scope changes
   â€¢ Test Performance: {time} total execution
   â€¢ CI/CD: {status}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ RECOMMENDED ACTIONS

ğŸ”´ Critical (Do Immediately):
   {list or "âœ“ None - story is healthy"}

ğŸŸ¡ Important (Before Next Story):
   {list}

ğŸŸ¢ Nice to Have (Backlog):
   {list}

ğŸ‰ Celebrate:
   {list positive achievements}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ DOCUMENTS UPDATED

âœ“ docs/qa/assessments/{story-id}-health-assessment-{date}.md
âœ“ docs/tech-debt.md
{âœ“ docs/type-ignore-registry.md (if applicable)}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š QUALITY GATES

Story Completion: {âœ…/âŒ}
Code Quality: {âœ…/âŒ}
Debt Management: {âœ…/âŒ}

Overall Status: {âœ… PASS / âš ï¸ PASS WITH NOTES / âŒ FAIL}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’¡ QUICK COMMANDS

# View full assessment
cat docs/qa/assessments/{story-id}-health-assessment-{date}.md

# View tech debt tracker
cat docs/tech-debt.md

# View coverage details
uv run pytest tests/stories/{story-id}/ --cov=src/momo --cov-report=html
open htmlcov/index.html

# Re-run quality checks
uv run mypy src/ tests/
uv run ruff check .
uv run pytest tests/stories/{story-id}/ -v

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## Scoring Rubrics

### Value Delivery Score (0-100)

**Components:**
- Production code volume (30%): Based on LOC, functions, files added
- Test coverage expansion (30%): Based on test LOC, test count, test/code ratio
- Documentation quality (20%): Based on docstrings, README, ADRs
- AC completion (20%): Based on acceptance criteria completion rate

**Calculation:**
- 100: All AC completed, excellent test/code ratio (â‰¥1.5), comprehensive docs
- 80-99: Most AC completed, good test coverage, adequate docs
- 60-79: Some AC incomplete, moderate test coverage, minimal docs
- 40-59: Many AC incomplete, poor test coverage, no docs
- 0-39: Minimal value delivered

### Code Quality Score (0-100)

**Components:**
- Complexity (40%): Cyclomatic complexity, maintainability index
- Type coverage (30%): Percentage of functions with full type hints
- Duplication (30%): Number of duplicate patterns detected

**Complexity Scoring:**
- 100: All functions CC < 5, MI > 80
- 80-99: Most functions CC < 10, MI > 60
- 60-79: Some functions CC 10-15, MI 40-60
- 40-59: Many functions CC > 15, MI < 40
- 0-39: Extreme complexity, MI < 20

### Technical Debt Score (0-100)

Higher score = less debt (inverted from V1 thinking)

**Components:**
- Type safety (30%): Net type ignores added
- Code organization (25%): Net TODOs added
- Architecture (30%): Violation count
- Test infrastructure (15%): Fixture/marker issues

**Calculation:**
- 100: 0 net debt added, 0 violations
- 90-99: 1-2 minor items, 0 violations
- 70-89: 3-5 items, 1 minor violation
- 50-69: 6-10 items, 2-3 violations
- 0-49: 10+ items or critical violations

### Debt Repayment Score (0-100)

**Components:**
- Debt items resolved (50%): Type ignores removed, TODOs resolved
- Refactoring volume (30%): Files with net LOC reduction
- Test cleanup (20%): Obsolete tests removed, fixtures consolidated

**Calculation:**
- 100: 5+ debt items resolved, significant refactoring
- 80-99: 3-4 debt items resolved, moderate refactoring
- 60-79: 1-2 debt items resolved
- 40-59: Minimal debt repayment
- 0-39: No debt repayment activity

### Security Posture Score (0-100)

**Components:**
- Dependency risk (40%): New dependencies added
- Security patterns (40%): Hardcoded secrets, injection risks
- Sensitive file handling (20%): .env, credentials files

**Calculation:**
- 100: 0 new deps, 0 security patterns, 0 sensitive files
- 80-99: 1-2 new deps (vetted), 0 security issues
- 60-79: 3-5 new deps, 1-2 minor patterns (false positives)
- 40-59: 5+ new deps, 3+ patterns
- 0-39: Critical security issues detected

### Process Health Score (0-100)

**Components:**
- Commit quality (30%): Fix/rollback ratio
- Scope discipline (25%): Out-of-scope changes
- Test performance (25%): Test execution time trends
- CI/CD stability (20%): Pipeline changes

**Calculation:**
- 100: 0% fix ratio, perfect scope, fast tests, stable CI
- 80-99: <10% fix ratio, 1 out-of-scope change, reasonable test time
- 60-79: 10-20% fix ratio, 2-3 out-of-scope changes
- 40-59: 20-30% fix ratio, significant scope drift
- 0-39: >30% fix ratio, major scope/CI issues

### Overall Health Score

Weighted average:
- Value Delivery: 25%
- Code Quality: 20%
- Technical Debt: 20% (inverted - higher = better)
- Debt Repayment: 15%
- Security Posture: 10%
- Process Health: 10%

**Total: 100%**

---

## Error Handling

If any check fails:
1. Document the failure in assessment report
2. Mark category as "Unable to Assess - [reason]"
3. Provide manual verification commands
4. Continue with remaining checks
5. Note limitation in executive summary

---

## Success Criteria

Assessment succeeds when:
1. âœ… All 8 analysis phases complete (with or without findings)
2. âœ… Comprehensive assessment report created
3. âœ… docs/tech-debt.md updated
4. âœ… docs/type-ignore-registry.md updated (if applicable)
5. âœ… Summary report displayed with actionable recommendations
6. âœ… All scoring calculations documented
7. âœ… Quality gate status determined

---

## Migration from V1

**Key Differences:**
- V1: Deficit-focused (what's wrong)
- V2: Balanced (value + quality + debt + process)

**V1 checks preserved:**
- All technical debt checks (type ignores, TODOs, architecture, test infrastructure)
- Document structure (tech-debt.md, type-ignore-registry.md)
- Scoring rubrics (enhanced)

**V2 additions:**
- Value delivery metrics
- Code quality analysis
- Debt repayment tracking (net change, not just additions)
- Security analysis
- Performance analysis
- Process health metrics
- Quality gates
- Trend analysis

**Backward Compatibility:**
- V2 documents are supersets of V1
- V1 tools can still read V2 tech-debt.md updates
- V2 scoring is more comprehensive but doesn't break V1 expectations

---

## Notes

- This assessment is **advisory, not blocking** (unless quality gates fail)
- Findings inform planning for next story
- Low-scoring stories may need cleanup before proceeding
- Assessment documents become input for refactoring stories
- **Balance is key:** Low debt + low value = scope too small
- **Trade-offs are OK:** Some debt is acceptable if high value delivered
- Run immediately after story completion, before starting next story

---

**Philosophy:** In an AI-agent-first workflow, celebrate wins, measure quality, track debt, and improve systematically. Assess the whole story, not just the problems.

---

## V2 Improvements & Fixes Applied

### Robustness & Error Handling

**Variable Validation:**
- âœ… Added `STORY_ID` environment variable validation in Phase 0
- âœ… Added planning commit existence check with clear error messages
- âœ… All wc/grep commands now use `|| echo "0"` fallback pattern
- âœ… All arithmetic operations use `${VAR:-0}` safe default pattern
- âœ… Added file existence checks before reading story/test-design files

**Safe Arithmetic:**
- âœ… Fixed type ignore counting to prevent bash arithmetic errors on empty results
- âœ… Fixed TODO/FIXME counting with safe numeric defaults
- âœ… Added fix ratio calculation with divide-by-zero protection
- âœ… All counts now properly initialized before arithmetic operations

**Non-Destructive Git Operations:**
- âœ… Eliminated `git checkout` in baseline metrics (Phase 1.3) - now uses `git grep` and `git show`
- âœ… Eliminated `git checkout` in coverage delta (Phase 9.2) - baseline now optional
- âœ… Working directory remains unchanged throughout assessment
- âœ… Safe for running on dirty working trees

**Tool Availability:**
- âœ… Added prerequisites check (Phase 0) for required and optional tools
- âœ… Graceful degradation when radon not installed (complexity analysis)
- âœ… Graceful degradation when uv not available (test/coverage)
- âœ… Clear SKIPPED messages when tools or directories missing

### Consistency & Clarity

**Placeholder Standardization:**
- âœ… Bash variables: `${STORY_ID}`, `${PLANNING_COMMIT}`, etc.
- âœ… File path placeholders: `{story-id}` in documentation
- âœ… Clear documentation of placeholder formats in Prerequisites section

**State Management:**
- âœ… Added state file (`/tmp/assess-{story-id}-state-$$.sh`) for variable persistence
- âœ… All important variables saved to state file for cross-phase access
- âœ… Automatic cleanup on exit via trap

**Temporary File Handling:**
- âœ… Fixed `/tmp/story-ac.txt` collision - now uses unique PID-based names
- âœ… All temp files use `${STORY_ID}` and `$$` for uniqueness
- âœ… Proper cleanup of temporary files

**Progress Indicators:**
- âœ… Added "Phase X/11" indicators to all phases
- âœ… Added time estimates (est. 30s, 1-2 min, etc.) for each phase
- âœ… Total estimated time: 5-10 minutes displayed at start
- âœ… Clear progress tracking throughout assessment

### Project-Specific Adaptations

**Architecture Compliance (Phase 4.3):**
- âœ… Clearly marked as Momo-specific examples
- âœ… Added conditional check for `src/momo` directory
- âœ… SKIPPED message when not in Momo project
- âœ… Instructions to customize for other projects

**Security Patterns (Phase 6.2):**
- âœ… Added "HEURISTIC" warnings for all security pattern checks
- âœ… Emphasized need for manual review of findings
- âœ… Clear expectation of false positives
- âœ… Counts displayed with warning emoji (âš ï¸) to indicate review needed

**Coverage Analysis (Phase 9):**
- âœ… Changed from `--cov=src/momo` to `--cov=src` (more generic)
- âœ… Baseline coverage marked as optional (challenging without checkout)
- âœ… Clear note about manual baseline measurement if desired

### Usability Improvements

**Prerequisites Section:**
- âœ… New Phase 0 with comprehensive environment validation
- âœ… Clear list of required vs. optional tools
- âœ… Environment variable setup instructions
- âœ… Tool availability checks with actionable error messages

**Date Handling:**
- âœ… `ASSESSMENT_DATE` variable automatically set via `date +%Y%m%d`
- âœ… Used consistently in file naming and reports
- âœ… No manual date placeholder needed

**Error Messages:**
- âœ… Clear, actionable error messages for missing STORY_ID
- âœ… Expected commit message format shown when planning commit not found
- âœ… File paths shown in warnings when files not found
- âœ… Installation instructions provided when tools missing

### Code Quality

**Defensive Programming:**
- âœ… All grep commands redirect stderr to `/dev/null` or handle errors
- âœ… All file operations check existence first
- âœ… All directory operations include `-p` flag (create if needed)
- âœ… Proper quoting of variables with special characters

**Output Clarity:**
- âœ… Consistent output format across phases
- âœ… Clear section headers with echo separators
- âœ… Counts displayed in structured format
- âœ… Success/skip/warning indicators (âœ“, SKIPPED, âš ï¸)

### What's Still TODO (Known Limitations)

**Not Fixed (By Design):**
- Baseline coverage measurement still requires git checkout or worktree (complex, marked optional)
- Heuristic patterns (grep for `def`, `class`, security) still have false positives (documented)
- Momo-specific architecture checks (intentionally project-specific, well-documented)
- No automated scoring calculation (requires manual analysis, out of scope for shell script)

**Future Enhancements (Out of Scope):**
- Automated score calculation from metrics
- Interactive mode for clarifying ambiguous findings
- HTML report generation
- Integration with CI/CD pipelines
- Historical trend tracking across multiple stories

---

## Migration Notes from Original Draft

If you used the original V2 draft, here's what changed:

1. **Set `STORY_ID` before running:** `export STORY_ID="1.2"`
2. **No more destructive git checkout** - safe to run on any working tree
3. **All commands now have safe fallbacks** - won't crash on empty results
4. **Project-specific checks clearly marked** - customize for your project
5. **Optional tool checks added** - graceful degradation when tools missing
6. **Progress indicators** - you'll see which phase is running and time estimates

The assessment is now production-ready and robust for automated execution.
